{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not os.path.exists(f'{os.getcwd()}\\DryBeanDataset')):\n",
    "    download_dataset('https://archive.ics.uci.edu/ml/machine-learning-databases/00602/DryBeanDataset.zip', '.')\n",
    "df = load_dataset(\"DryBeanDataset/Dry_Bean_Dataset.xlsx\")\n",
    "df = df['Dry_Beans_Dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, \"\\n\\n\", df.columns, \"\\n\\n\", df[\"Class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enconding, i = {}, 0\n",
    "for label in df[\"Class\"].unique():\n",
    "    enconding[label] = i\n",
    "    i=i+1\n",
    "\n",
    "print(enconding)\n",
    "df.Class.replace(enconding, inplace=True)\n",
    "df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset possui classes desbanlanceadas, é esperado que o modelo perfome bem para a classe DERMASON e não tão bem para o BOMBAY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n",
    "       'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent',\n",
    "       'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2',\n",
    "       'ShapeFactor3', 'ShapeFactor4']]\n",
    "y = df['Class']\n",
    "y_labels = list(enconding.keys()) #y_labels = ['DERMASON','SIRA','SEKER','HOROZ','CALI','BARBUNYA','BOMBAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(layers, dropout=False):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(layers[0],)))\n",
    "    model.add(Dense(units=layers[1], input_shape=(layers[0],), activation='tanh'))\n",
    "    for layer in layers[2::]:\n",
    "        model.add(Dense(units=layer, activation='tanh'))\n",
    "    if dropout:\n",
    "        model.add(Dropout(.2))\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    # Train\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferencia_MLP(X, y, clf, scaler):\n",
    "\n",
    "  X, y = scaler.transform(X), y\n",
    "  predictions = clf.predict(X)\n",
    "  class_predictions = np.argmax(predictions, axis = 1).reshape(-1,1) \n",
    "  cm = confusion_matrix(y_true = y, y_pred = class_predictions)\n",
    "  val_acc = np.trace(cm)/np.sum(cm)*100\n",
    "    \n",
    "  return val_acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferencia_Linear(X, y, clf):\n",
    "    \n",
    "  class_predictions = clf.predict(X).reshape(-1,1)\n",
    "  cm = confusion_matrix(y_true = y, y_pred = class_predictions)    \n",
    "  val_acc = np.trace(cm)/np.sum(cm)*100\n",
    "  \n",
    "  return val_acc, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODELS #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train,y_train, X_test, y_test, mlp_size):\n",
    "    classifiers = [\n",
    "        MLP(mlp_size),\n",
    "        LDA()\n",
    "    ]\n",
    "    names = [\n",
    "        \"MLP\",\n",
    "        \"LDA\"\n",
    "    ]\n",
    "    acc_dict = {\n",
    "        \"MLP\": [],\n",
    "        \"LDA\": []\n",
    "    }\n",
    "    cm_dict = {\n",
    "        \"MLP\": [],\n",
    "        \"LDA\": []\n",
    "    }\n",
    "\n",
    "    # Redução de Dim\n",
    "    # X_train, X_test = LDA_reduction(X_train, y_train, X_test, 3)\n",
    "\n",
    "    # Normalize data for MLP\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    X_scaled = scaler.fit_transform(X_train.to_numpy()) ## to_numpy opcional, funciona com df\n",
    "\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        if(name!=\"MLP\"):\n",
    "            clf.fit(X_scaled, y_train)\n",
    "            val_acc, cm = inferencia_Linear(scaler.transform(X_test), y_test, clf)\n",
    "            acc_dict[name] = val_acc\n",
    "            cm_dict[name] = cm        \n",
    "            # print(f'Acurácia de Test {name}: {val_acc}')\n",
    "        else:\n",
    "            mlp_model = clf.fit(\n",
    "                x=X_scaled,\n",
    "                y=y_train,\n",
    "                validation_split=0,\n",
    "                batch_size=16,\n",
    "                epochs=1,\n",
    "                verbose=0)\n",
    "            val_acc, cm = inferencia_MLP(X_test, y_test, clf, scaler)\n",
    "            acc_dict[name] = val_acc\n",
    "            cm_dict[name] = cm     \n",
    "            # print(f'Acurácia de Test {name}: {val_acc}')\n",
    "        # print()\n",
    "    \n",
    "    return acc_dict, cm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accs_dict e cms_dict serão um dict com uma lista representando a acuracia e a matrix de confusao para cada teste rodado. Cada lista tem tamanho N_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Best Configuration MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_multlayer_acc = []\n",
    "LDA_multlayer_acc = []\n",
    "for layer1 in range(1,10):\n",
    "    for layer2 in range(1,10):\n",
    "        mlp_size = [16,layer1, layer2]\n",
    "        N_test = 20 ## numero de tests a serem feitos, idealmente é sempre bom ter no minimo 20 amostras.\n",
    "        accs_dict = { \n",
    "            \"MLP\": [],\n",
    "            \"LDA\": []\n",
    "        }\n",
    "        cms_dict = {\n",
    "            \"MLP\": [],\n",
    "            \"LDA\": []\n",
    "        }\n",
    "\n",
    "        for i in range(N_test):\n",
    "            # print(f'Teste {i+1}')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random.randint(0,1000))\n",
    "            acc, cm = train(X_train, y_train, X_test, y_test, mlp_size)\n",
    "            [accs_dict[k].append(acc[k]) for k, v in acc.items()]\n",
    "            [cms_dict[k].append(cm[k]) for k, v in cm.items()]   \n",
    "\n",
    "        MLP_acc = accs_dict['MLP'] ## Last configuration saved\n",
    "        LDA_acc = accs_dict['LDA'] ## Last configuration saved\n",
    "        MLP_multlayer_acc.append((np.round(np.mean(MLP_acc), 2), np.round(np.std(MLP_acc), 2)))\n",
    "        print(f'Layer conf: {mlp_size}')\n",
    "        print(f'MLP: {np.round(np.mean(MLP_acc), 2)} ± {np.round(np.std(MLP_acc), 2)}')\n",
    "        print(f'LDA: {np.round(np.mean(LDA_acc), 2)} ± {np.round(np.std(LDA_acc), 2)}') \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acurácia média e Desvio padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_acc = accs_dict['MLP']\n",
    "LDA_acc = accs_dict['LDA']\n",
    "\n",
    "print(f'MLP: {np.round(np.mean(MLP_acc), 2)} ± {np.round(np.std(MLP_acc), 2)}')\n",
    "print(f'LDA: {np.round(np.mean(LDA_acc), 2)} ± {np.round(np.std(LDA_acc), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix de Confusão resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[4601    4    0    0    3  132  343]\n",
      " [ 134 1231   43 1198  294  345    9]\n",
      " [   0  154  720  419    0    0    0]\n",
      " [   8  177    1 3328  464   73    0]\n",
      " [   0    2    0   82 4655   97   63]\n",
      " [ 111    2    0    7  381 4099 1992]\n",
      " [ 125    0    0    0    7  166 8560]]\n"
     ]
    }
   ],
   "source": [
    "MLP_cm = (np.sum([i for i in cms_dict['MLP']], 0)).astype(int)\n",
    "name = 'MLP'\n",
    "Plot_confusion_matrix(cm=MLP_cm, classes=y_labels, title=f'Matriz de Confusão {name}', normalize=False, save_file=(True, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[4649   28    0    0    0  321   85]\n",
      " [  23 2710    0  283   14  224    0]\n",
      " [   0    0 1291    2    0    0    0]\n",
      " [   6   27    0 3859   49  110    0]\n",
      " [   0   11    0  111 4571  193   13]\n",
      " [  11   15    0    7   50 6181  328]\n",
      " [ 123    5    0    0   12 1166 7552]]\n"
     ]
    }
   ],
   "source": [
    "LDA_cm = (np.sum([i for i in cms_dict['LDA']], 0)).astype(int)\n",
    "name = 'LDA'\n",
    "Plot_confusion_matrix(cm=LDA_cm, classes=y_labels, title=f'Matriz de Confusão {name}', normalize=False, save_file=(True, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes de Significancia #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checando a Distribuição\n",
    "\n",
    "Valido para N_testes de uma mesma amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = scipy.stats.normaltest(MLP_acc)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"MLP: Distribuição não normal\")\n",
    "else:\n",
    "    print(\"MLP: Distribuição normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = scipy.stats.normaltest(LDA_acc)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"LDA: Distribuição não normal\") # rejeitando\n",
    "else:\n",
    "    print(\"LDA: Distribuição normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametricos (NORMAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "stat, p = ttest_ind(MLP_acc, LDA_acc)\n",
    "print('stat=%.3f, p=%.5f' % (stat, p))\n",
    "if p < alpha:\n",
    "\tprint('Probably different distributions') # rejeita null\n",
    "else:\n",
    "\tprint('Probably the same distribution')\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diria que esse é o teste correto para essa situação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "stat, p = f_oneway(MLP_acc, LDA_acc)\n",
    "print('stat=%.3f, p=%.5f' % (stat, p))\n",
    "if p < alpha: ## null hipotesis: x1 and x2 pertencem a mesma distribuição\n",
    "\tprint('Probably different distributions') # rejeita null\n",
    "else:\n",
    "\tprint('Probably the same distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Não parametricos (não NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p = mannwhitneyu(MLP_acc, LDA_acc)\n",
    "print('stat=%.3f, p=%.5f' % (stat, p))\n",
    "if p < alpha: ## null hipotesis: x1 and x2 pertencem a mesma distribuição\n",
    "\tprint('Probably different distributions') # rejeita null\n",
    "else:\n",
    "\tprint('Probably the same distribution')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f39fc709f676cd84dd49a8bcc36917e4a92a6628bc5fa4d57d105b7afdb2108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
